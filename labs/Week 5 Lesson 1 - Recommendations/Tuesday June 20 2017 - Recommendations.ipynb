{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engines - MovieLens Data\n",
    "\n",
    "## Tuesday June 20 2017\n",
    "\n",
    "MovieLens data sets were collected by the GroupLens Research Project at the University of Minnesota.\n",
    "\n",
    "This data set consists of: * 100,000 ratings (1-5) from 943 users on 1682 movies. * Each user has rated at least 20 movies. * Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "The data was collected through the MovieLens web site (movielens.umn.edu) during the seven-month period from September 19th, 1997 through April 22nd, 1998. This data has been cleaned up - users who had less than 20 ratings or did not have complete demographic information were removed from this data set. Detailed descriptions of the data file can be found at the end of this file.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Load the data into the recommendation format\n",
    "2. Build and assess model accuracy\n",
    "3. Make individual recommendations\n",
    "4. Try multiple models and compare accuracy\n",
    "5. Consider how a company could use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Install Surpise - a useful library for recommendation engines\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Surprise\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Load the data into the recommendation format\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path = '../../data/u.data', reader=reader)\n",
    "data.split(n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Build and assess model accuracy\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Make individual recommendations\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. Try multiple models and compare accuracy\n",
    "\n",
    "# Try at least 3 of the models mentioned below:\n",
    "#random_pred.NormalPredictor    Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "#baseline_only.BaselineOnly    Algorithm predicting the baseline estimate for given user and item.\n",
    "#knns.KNNBasic    A basic collaborative filtering algorithm.\n",
    "#knns.KNNWithMeans    A basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "#knns.KNNBaseline    A basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "#matrix_factorization.SVD    The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.\n",
    "#matrix_factorization.SVDpp    The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "#matrix_factorization.NMF    A collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "#slope_one.SlopeOne    A simple yet accurate collaborative filtering algorithm.\n",
    "#co_clustering.CoClustering    A collaborative filtering algorithm based on co-clustering.\n",
    "\n",
    "\n",
    "# Here's how to run Non-Negative Matrix Factorisiation\n",
    "from surprise import NMF\n",
    "\n",
    "# Now we will try Non-Negative Matrix Factorisiation (a form of collaborative filtering)\n",
    "algo.NMF = NMF()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf.NMF = evaluate(algo.NMF, data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf.NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Consider how a company could use this\n",
    "\n",
    "How might a company use a recommendation like this in practice? Write a few paragraphs covering how they could use the above covering:\n",
    "- How the algorithm works?\n",
    "- What data would be used?\n",
    "- How would we know if it's working?\n",
    "- What is the benefit of using an algorithm over this over just recommending the most popular films overall?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
